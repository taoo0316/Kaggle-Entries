{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a73ec5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zwt2000/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/zwt2000/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/zwt2000/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#for text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "#for model-building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#for word embedding\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "489d1b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train= pd.read_csv('train.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "512e435e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  \n",
       "0                    Just happened a terrible car crash  \n",
       "1     Heard about #earthquake is different cities, s...  \n",
       "2     there is a forest fire at spot pond, geese are...  \n",
       "3              Apocalypse lighting. #Spokane #wildfires  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan  \n",
       "...                                                 ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
       "3259  Storm in RI worse than last hurricane. My city...  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...  \n",
       "\n",
       "[3263 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=pd.read_csv('test.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1ab9ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4342\n",
      "1    3271\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='target'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=df_train['target'].value_counts()\n",
    "print(x)\n",
    "sns.barplot(x.index,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a0cea54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e300a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    " \n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5aedd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zwt2000/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edf88aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>get sent photo ruby alaska smoke wildfires pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         clean_text  \n",
       "0       1         deed reason earthquake may allah forgive u  \n",
       "1       1              forest fire near la ronge sask canada  \n",
       "2       1  resident ask shelter place notify officer evac...  \n",
       "3       1  people receive wildfire evacuation order calif...  \n",
       "4       1  get sent photo ruby alaska smoke wildfires pou...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "df_train['clean_text'] = df_train['text'].apply(lambda x: finalpreprocess(x))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb6a76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[\"clean_text\"],df_train[\"target\"],test_size=0.2,shuffle=True)\n",
    "#Word2Vec\n",
    "# Word2Vec runs on tokenized sentences\n",
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5ebb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f144575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e54782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       870\n",
      "           1       0.82      0.71      0.76       653\n",
      "\n",
      "    accuracy                           0.81      1523\n",
      "   macro avg       0.81      0.80      0.80      1523\n",
      "weighted avg       0.81      0.81      0.81      1523\n",
      "\n",
      "Confusion Matrix: [[767 103]\n",
      " [187 466]]\n",
      "AUC: 0.8627633732903839\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using SVM(tf-idf)\n",
    "clf.fit(X_train_vectors_tfidf, y_train)  \n",
    "#Predict y value for test dataset\n",
    "y_predict = clf.predict(X_test_vectors_tfidf)\n",
    "y_prob = clf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c92038e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bef696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:35:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train_vectors_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a32241d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       870\n",
      "           1       0.82      0.65      0.72       653\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.80      0.77      0.78      1523\n",
      "weighted avg       0.79      0.79      0.78      1523\n",
      "\n",
      "Confusion Matrix: [[779  91]\n",
      " [231 422]]\n",
      "AUC: 0.8374698561898224\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_test_vectors_tfidf)\n",
    "y_prob = model.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ab19631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:47:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svm', SVC(probability=True)),\n",
       "                             ('xgboost',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            enable_categorical=False, gamma=0,\n",
       "                                            gpu_id=-1, importance_type=None,\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.300000012,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            min_child_weight=1, missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=4,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=0,\n",
       "                                            reg_alpha=0, reg_lambda=1,\n",
       "                                            scale_pos_weight=1, subsample=1,\n",
       "                                            tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "estimators.append(('svm', clf))\n",
    "estimators.append(('xgboost', model))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators,voting=\"soft\")\n",
    "ensemble.fit(X_train_vectors_tfidf,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3101611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  target\n",
      "0   0       1\n",
      "1   2       1\n",
      "2   3       1\n",
      "3   9       0\n",
      "4  11       1\n"
     ]
    }
   ],
   "source": [
    "#Pre-processing the new dataset\n",
    "df_test['clean_text'] = df_test['text'].apply(lambda x: finalpreprocess(x)) #preprocess the data\n",
    "X_test=df_test['clean_text'] \n",
    "#converting words to numerical data using tf-idf\n",
    "X_vector=tfidf_vectorizer.transform(X_test)\n",
    "#use the best model to predict 'target' value for the new dataset \n",
    "y_predict = ensemble.predict(X_vector)      \n",
    "y_prob = ensemble.predict_proba(X_vector)[:,1]\n",
    "df_test['predict_prob']= y_prob\n",
    "df_test['target']= y_predict\n",
    "final=df_test[['id','target']].reset_index(drop=True)\n",
    "print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5658f85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully completed! \n"
     ]
    }
   ],
   "source": [
    "final.to_csv('submission.csv',index = False)\n",
    "print(\" Successfully completed! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5b05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
